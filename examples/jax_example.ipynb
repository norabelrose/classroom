{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting a reward model offline**\n",
    "\n",
    "In this example, we'll train a vanilla PPO agent on the Brax Ant environment using the \"ground truth\" reward provided by the environment. We'll then fit a reward model to the resulting clips.\n",
    "\n",
    "In order to do this, we'll need to \"record\" a subset of the environment states visited by the agent during the training process. For this we can use the `BraxRecorder` environment wrapper class, which uses JAX host callbacks to efficiently record these states without interrupting Brax's wicked fast all-GPU training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brax.envs import create_fn\n",
    "from brax.training import ppo\n",
    "from classroom.brax import BraxRecorder\n",
    "import numpy as np\n",
    "\n",
    "train_sps = []\n",
    "\n",
    "def progress(_, metrics):\n",
    "    train_sps.append(metrics['speed/sps'])\n",
    "\n",
    "def env_fn(name: str, db_path: str):\n",
    "    brax_fn = create_fn(env_name=name)\n",
    "    return lambda *args, **kwargs: BraxRecorder(brax_fn(*args, **kwargs), db_path)\n",
    "\n",
    "\n",
    "ppo.train(\n",
    "    environment_fn=env_fn('ant', '~/classroom/ant'), num_timesteps = 30_000_000,\n",
    "    log_frequency = 10, reward_scaling = .1, episode_length = 1000,\n",
    "    normalize_observations = True, action_repeat = 1, unroll_length = 5,\n",
    "    num_minibatches = 32, num_update_epochs = 4, discounting = 0.97,\n",
    "    learning_rate = 3e-4, entropy_cost = 1e-2, num_envs = 2048,\n",
    "    batch_size = 1024, progress_fn = progress\n",
    ")\n",
    "\n",
    "print(f'train steps/sec: {np.mean(train_sps[1:])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you like, you can now use the Classroom GUI to input your own preferences on the resulting clips. For this example, though, we'll simulate the human preference feedback by stochastically generating preferences based on the ground truth rewards. `SyntheticPairwisePrefs` samples the preference for each pair of clips from a mixture distribution with two components:\n",
    "- a distribution based on the [Bradley-Terry model](https://en.wikipedia.org/wiki/Bradley%E2%80%93Terry_model) of pairwise comparison, where the probability of preferring A to B is equal to the sigmoid of the difference in \"scores\" of A and B, and\n",
    "- a uniform distribution over the two clips, representing the possibility of the human making a \"mistake\" and selecting a clip at random.\n",
    "\n",
    "The \"scores\" for the Bradley-Terry distribution are the rescaled sums of rewards for each clip. `SyntheticPairwisePrefs` normalizes the rewards to zero mean and unit variance, then scales them by a \"rationality\" parameter Î² which defaults to 5.0. You can also choose the weight assigned to the mistake distribution with the `mistake_prob` parameter; by default it is set to 0.1.\n",
    "\n",
    "Note that the total number of pairwise comparisons in any dataset scales quadratically with the dataset size, which could easily get unwieldy with even medium-size datasets. Training a model on all `N(N - 1) // 2` pairs of clips could also lead to overfitting since the model will see each clip many times per epoch. To prevent this, `SyntheticPairwisePrefs` samples a subset of `N` clip pairs _without replacement_ by shuffling the dataset and creating pairs from adjacent clips in the shuffled dataset. The random seed used to sample clip pairs and preferences can be set using the `seed` parameter and defaults to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classroom.datasets import SyntheticPairwisePrefs, SyntheticListwisePrefs\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "ds = SyntheticPairwisePrefs(\n",
    "    '/home/nora/value-learning/ant/seed_0',\n",
    "    # batch_size=64,\n",
    "    # mistake_prob=0.01,\n",
    "    transform=lambda x: np.concatenate([x.state.obs, x.action], axis=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classroom.datasets import BatchedDataset, SubsetDataset\n",
    "import numpy as np\n",
    "\n",
    "indices = np.random.permutation(len(ds))\n",
    "test_size = round(len(ds) * 0.2)\n",
    "\n",
    "test = SubsetDataset(ds, indices[:test_size])\n",
    "# val = SubsetDataset(ds, indices[test_size:test_size * 2])\n",
    "# train = SubsetDataset(ds, indices[test_size * 2:])\n",
    "val = BatchedDataset(SubsetDataset(ds, indices[test_size:test_size * 2]), 64)\n",
    "train = BatchedDataset(SubsetDataset(ds, indices[test_size * 2:]), 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend implementing your preference model as a subclass of `classroom.jax.PairwisePrefModel` if possible, since this base class implements most of the training loop boilerplate code for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classroom.jax import ListwisePrefModel, PairwisePrefModel\n",
    "import flax.linen as nn\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "class MlpPrefModel(PairwisePrefModel):\n",
    "    hidden_layers: list[int]\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n",
    "        for size in self.hidden_layers:\n",
    "            x = nn.Dense(size)(x)\n",
    "            x = nn.activation.relu(x)\n",
    "            # x = nn.Dropout(0.1)(x, deterministic=eval)\n",
    "        \n",
    "        # scores, var = RandomFeatureGaussianProcess(1)(x)\n",
    "        scores = nn.Dense(1)(x)\n",
    "        return jnp.mean(scores.squeeze(-1), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model is as simple as calling `model.fit()` with your training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train loss: 0.659 val accuracy: 0.856 val loss: 0.613\n",
      "Epoch 2 train loss: 0.576 val accuracy: 0.863 val loss: 0.533\n",
      "Epoch 3 train loss: 0.499 val accuracy: 0.866 val loss: 0.455\n",
      "Epoch 4 train loss: 0.433 val accuracy: 0.866 val loss: 0.393\n",
      "Epoch 5 train loss: 0.390 val accuracy: 0.872 val loss: 0.353\n",
      "Epoch 6 train loss: 0.370 val accuracy: 0.878 val loss: 0.333\n",
      "Epoch 7 train loss: 0.363 val accuracy: 0.875 val loss: 0.323\n",
      "Epoch 8 train loss: 0.360 val accuracy: 0.875 val loss: 0.319\n",
      "Epoch 9 train loss: 0.358 val accuracy: 0.875 val loss: 0.316\n",
      "Epoch 10 train loss: 0.357 val accuracy: 0.875 val loss: 0.314\n",
      "Epoch 11 train loss: 0.355 val accuracy: 0.875 val loss: 0.313\n",
      "Epoch 12 train loss: 0.354 val accuracy: 0.872 val loss: 0.311\n",
      "Epoch 13 train loss: 0.352 val accuracy: 0.878 val loss: 0.310\n",
      "Epoch 14 train loss: 0.351 val accuracy: 0.881 val loss: 0.309\n",
      "Epoch 15 train loss: 0.350 val accuracy: 0.881 val loss: 0.308\n",
      "Epoch 16 train loss: 0.349 val accuracy: 0.884 val loss: 0.307\n",
      "Epoch 17 train loss: 0.348 val accuracy: 0.884 val loss: 0.306\n",
      "Epoch 18 train loss: 0.347 val accuracy: 0.881 val loss: 0.305\n",
      "Epoch 19 train loss: 0.346 val accuracy: 0.881 val loss: 0.304\n",
      "Epoch 20 train loss: 0.346 val accuracy: 0.881 val loss: 0.303\n",
      "Epoch 21 train loss: 0.345 val accuracy: 0.878 val loss: 0.303\n",
      "Epoch 22 train loss: 0.344 val accuracy: 0.878 val loss: 0.302\n",
      "Epoch 23 train loss: 0.343 val accuracy: 0.878 val loss: 0.302\n",
      "Epoch 24 train loss: 0.343 val accuracy: 0.878 val loss: 0.301\n",
      "Epoch 25 train loss: 0.342 val accuracy: 0.878 val loss: 0.301\n",
      "Epoch 26 train loss: 0.341 val accuracy: 0.878 val loss: 0.300\n",
      "Epoch 27 train loss: 0.340 val accuracy: 0.878 val loss: 0.300\n",
      "Epoch 28 train loss: 0.340 val accuracy: 0.878 val loss: 0.300\n",
      "Epoch 29 train loss: 0.339 val accuracy: 0.875 val loss: 0.299\n",
      "Epoch 30 train loss: 0.338 val accuracy: 0.875 val loss: 0.299\n",
      "Epoch 31 train loss: 0.337 val accuracy: 0.875 val loss: 0.299\n",
      "Epoch 32 train loss: 0.337 val accuracy: 0.878 val loss: 0.298\n",
      "Epoch 33 train loss: 0.336 val accuracy: 0.878 val loss: 0.298\n",
      "Epoch 34 train loss: 0.335 val accuracy: 0.872 val loss: 0.298\n",
      "Epoch 35 train loss: 0.334 val accuracy: 0.875 val loss: 0.298\n",
      "Epoch 36 train loss: 0.334 val accuracy: 0.875 val loss: 0.297\n",
      "Epoch 37 train loss: 0.333 val accuracy: 0.875 val loss: 0.297\n",
      "Epoch 38 train loss: 0.332 val accuracy: 0.875 val loss: 0.297\n",
      "Epoch 39 train loss: 0.331 val accuracy: 0.875 val loss: 0.297\n",
      "Epoch 40 train loss: 0.331 val accuracy: 0.875 val loss: 0.297\n",
      "Epoch 41 train loss: 0.330 val accuracy: 0.875 val loss: 0.297\n",
      "Epoch 42 train loss: 0.329 val accuracy: 0.875 val loss: 0.297\n",
      "Epoch 43 train loss: 0.328 val accuracy: 0.878 val loss: 0.297\n",
      "Epoch 44 train loss: 0.327 val accuracy: 0.878 val loss: 0.297\n",
      "Epoch 45 train loss: 0.327 val accuracy: 0.878 val loss: 0.297\n",
      "Epoch 46 train loss: 0.326 val accuracy: 0.878 val loss: 0.297\n",
      "Epoch 47 train loss: 0.325 val accuracy: 0.878 val loss: 0.297\n",
      "Epoch 48 train loss: 0.324 val accuracy: 0.881 val loss: 0.297\n",
      "Epoch 49 train loss: 0.323 val accuracy: 0.881 val loss: 0.297\n",
      "Epoch 50 train loss: 0.322 val accuracy: 0.881 val loss: 0.297\n",
      "Early stopping; val loss plateaued at 0.297\n"
     ]
    }
   ],
   "source": [
    "model = MlpPrefModel([32, 16])\n",
    "state = model.fit(train, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kendalltau': 0.6655142748467353, 'loss': 2.486251}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply({'params': state.params}, test, method=model.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc1acdf2c20>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(\n",
    "    np.concatenate(rank_corr.scores, axis=0),\n",
    "    np.concatenate(rank_corr.labels, axis=0),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fa81541598839f570aad5dc7c0c2a1b79738f10fbd2c927ab4c8b970fa51d8f7"
  },
  "kernelspec": {
   "display_name": "Conda (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
